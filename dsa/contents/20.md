### Heap 堆的补充

<div align="center">
    <img width="800" src="./screenshot/101.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 从逻辑结构上理解堆是一种树形结构，这种树是一种几乎完美的树，也就是完全二叉树
  * 完全二叉树 complete binary tree
  * 特点是：
    * 在非(倒数第一和倒数第二)层结构上的节点都是孩子双全的
    * 在倒数第一和倒数第二层结构上的节点是没有分支或单分支的
    * 在倒数第二层：叶子节点必须紧密排列在右侧
    * 在倒数第一层：叶子节点必须紧密排列在左侧
    * 宏观上看就像是一棵三角形的树，在右下侧可能会有一定的缺失
    * 这就是完全二叉树，如上图树形结构所示
    * 如果没有单分支的节点(宏观上看右下侧没有缺失)叫做满二叉树 full complete binary tree
    * 满二叉树是完全二叉树的特例
- 完全二叉树可以非常有效的存储，可以排成一列，变成一个数组
    * 这样排好后会非常方便
    * 每一个节点的下标和它的两个孩子之间的关系是: 
    * 假如一个节点是1，那它的左孩子节点是1 x 2 + 1 = 3，右孩子节点是：1 x 2 + 2 = 4
    * 也就是节点下标是n，则左孩子节点下标是：2n+1, 右孩子节点下标是：2n+2
    * 用计算机表示：左孩子：Lc(n) = (n << 1) + 1, 右孩子：Rc(n) = (n+1) << 1 , 其中 << 表示左移
    * 上图下标排列成阶梯状的原因是暗示层与层之间的关系: 0是第一层；1，2是第二层；3，4，5，6是第三层 ...
- 在堆中有两类常规操作：insert(e) 和 getMax()
    * 插入和查找最大，两类操作相互配合就不那么直观了
    * 如果这些元素不是按下标来处理，而是有一个优先级的大小关系，那么把最大优先级的元素找出的效率往往关乎算法整体的效率
    * 如果每个都遍历一次来查询最大值, 其复杂度是O(n), 这几乎没有任何意义，我们期望它的复杂度是O(logn)
    * 大致如下图所示

<div align="center">
    <img width="800" src="./screenshot/102.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 堆顶元素r, 也就是树根(root), 我们认为r是优先级最高的元素，在物理上就存在那，这样getMax()和delMax()操作就非常的方便
- 当insert(e)的时候，我们要保持最大元素要动态的更新, 下面说下具体的更新做法
    * 简单的来说，更新的办法就是减而治之
    * 要把新元素放到最底部缺口的位置，如果没有缺口，则另起一行放到最下面，如上图一排第2个，就相当于在原来数组的最后新增了一个元素
    * 对比新节点和它的父节点的优先级关系，如上图一排第三个，在堆中，父节点的优先级一定比子节点的优先级高，如果不是，则要修复大小关系
    * 父节点下降一层，新节点上升一层，交换父子关系，按照这种思路逐一向上对比，如果关系顺了，则停下来，如果不顺则继续交换
    * 如上图一排的第四、第五，第这个过程可持续到树根的位置，这种做法叫做 shift up 或 percolate up (上滤操作)
- 反之，如果是删除操作，同样的道理
    * 直接删除树根节点，并将最末尾的节点补充到树根节点的位置，也就是删除r，将e补充到r的位置，这个过程如上图二排的1~3图
    * 这时候形式上恢复成了树形，但会破坏堆的有序性，为了维护有序性，在其孩子上找到一个最大的交而换之，重复这一过程，直到恢复堆的有序性。
    * 如上图二排的3~5，这个过程叫做 shift down 或 percolate down (下滤操作)
- 综上，我们可知道Heap的这种基本结构(其实Heap有很多种结构)
- 它的特点是：
    * 我们假想的用刚才那种对应方法，把存在于一个数组中的那些元素，逻辑上根据他们的rank(索引或下标)指定父子关系，比如：3和7,8; 5和11,12 ...
    * 也就是用一个数组实现逻辑上的一个树形结构
    * 然后在所有父子节点之间限定一下，它们的优先级上，父亲必须必儿子的优先级高
    * 那么我们知道优先级最高的元素只能在树根的位置(没有父节点)
- 我们可以看到，不管是上滤还是下滤操作，只需要logn步
    * 因为有n个节点构成的完全二叉树的高度在渐进上不会超过logn的
    * 每次交换都是常数，总共不到logn步，所以复杂度是O(logn)
- 以上通过堆的示例，我们首先知道了什么是减而治之的策略

### 减而治之的策略

**引例：愚公移山的故事**

- 太行、王屋二山，方七百里，高万仞，本在冀州之南，河阳之北。
- 北山愚公者，年且九十，面山而居。惩山北之塞，出入之迂也，聚室而谋曰：“吾与汝毕力平险，指通豫南，达于汉阴，可乎？”杂然相许。其妻献疑曰：“以君之力，曾不能损魁父之丘，如太行、王屋何？且焉置土石？”杂曰：“投诸渤海之尾，隐土之北。”遂率子孙荷担者三夫，叩石垦壤，箕畚运于渤海之尾。邻人京城氏之孀妻有遗男，始龀，跳往助之。寒暑易节，始一反焉。
- 河曲智叟笑而止之曰：“甚矣，汝之不惠！以残年余力，曾不能毁山之一毛，其如土石何？”北山愚公长息曰：“汝心之固，固不可彻，曾不若孀妻弱子。虽我之死，有子存焉。子又生孙，孙又生子；子又有子，子又有孙；子子孙孙无穷匮也，而山不加增，何苦而不平？”河曲智叟亡以应。
- 操蛇之神闻之，惧其不已也，告之于帝。帝感其诚，命夸娥氏二子负二山，一厝朔东，一厝雍南。自此，冀之南，汉之阴，无陇断焉。

**减而治之 (Decrease and Conquer)**

- 愚公移山的故事就是一个典型的减而治之的案例
- 山有一个定数，即它的problem size：n是一个定数
- 愚公一锹一镐一簸箕，一天一天的去做，总有一天可以把山挖平
- 而针对智叟的问题，愚公的解答方案是子子孙孙无穷匮也
- 而这个问题在现在来说，可以交给计算机去做，计算机是非常强大的工具，反复做一件事是计算机的长处
- 可见愚公是一个算法高手

**图例**

<div align="center">
    <img width="800" src="./screenshot/103.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 愚公的山就是一个problem, 而这个problem的size是n, 我们可以把它想象成非常大，比如1个亿，但是这也是一个定数
- 我们可以把问题规模分解成1和(n-1)两个, 之后的(n-1)可以再次分解成1和(n-2), ...
- 每个值为1的subproblem就是愚公的一筐土，这个过程就是 conquer
- 这种reduce的方案在算法设计中是一个非常典型的方案，我们称为减而治之

**二分查找 Binary Search**

- 有时候我们针对切分的粒度而言，一次subproblem并非是1，而是非常之大，规模为problem size的一半
- 伪代码：
    ```cpp
    // 基本类型为T的向量S，已经排好序的，预处理了
    // 查找目标为e
    // 查找范围lo ~ hi
    template <typename T> static Rank binSearch(T * S, T const & e, Rank lo, Rank hi) {
        // 不变性：A[0, lo) <= e < A[hi, n)
        while(lo < hi) {
            // 以中点为轴点，经比较后确定深入
            Rank mi = (lo + hi) >> 1;
            // [lo, mi) 或 (mi, hi) 貌似少了mi, 但是这样写即精练又准确: 向左向右都没有覆盖mi
            e < S[mi] ? hi = mi : lo = mi + 1;
        } // 出口时，A[lo=hi]为大于e的最小元素
        // 故lo - 1即不大于e的元素的最大秩
        return --lo;
    }
    ```

<div align="center">
    <img width="600" src="./screenshot/104.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- mi 是 lo ~ hi 的中点位置，已知lo,hi, 找到mi只需要O(1)的时间
- mi与目标元素e进行一次compare比较，如果相等就找到了停止
- 如果不等则根据大小关系寻找合适的位置(lo ~ mi) 或 (mi ~ hi)
- 重复这一过程，直到查找成功或失败
- 从这一过程来看，算法复杂度是O(logn)
- 这个问题我们要区分两种策略
    * decrease and conquer 减而治之：规模减少一半，处理一半，规模不断小
    * devide and conquer 分而治之：把一个分解为两个，每一个都要单独求解
    * 注意这是减而治之和分而治之的区别

**选择排序 Selectionsort**

<div align="center">
    <img width="600" src="./screenshot/105.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 上图示例就是选择排序的精髓
- 在任何时候，把长度为n的数列，以r为界，分成[0, r], (r, n)两部分，也就是前缀(prefix)和后缀(suffix)两部分
- 后缀在任何时候都是有序的，而无序的前缀中最大值也不会超过后缀的最小值(图中的M暗示前缀中的最大值Max)
- 接下来就是在前缀中找到这个Max最大值, 存入后缀中作为最小值，如上图所示
- 持续这个过程，整个序列将全部有序
- 我们可知，Selectionsort就是在prefix中进行select Max操作，找到之后将这个Max变为suffix的Min
- Selectionsort与Bubblesort本质上一致，不同点在于Selectionsort的前缀是均匀随机的，而Bubblesort处理前缀会消耗更多时间
- Bubblesort可以看做是Selectionsort的一种特例，其时间复杂度都是$O(n^2)$

**堆排序 Heapsort**

<div align="center">
    <img width="600" src="./screenshot/106.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 基于上面的Selectionsort，我们可知，如果继续进行优化，在前缀中的查找最大值这一过程可以使用一个特定的数据结构Heap堆，也就是Priority Queue
- 从最上面**Heap 堆的补充**内容可知，在前缀中查找最大这一过程可以将n优化为logn
- 整体的排序时间复杂度为 O(nlogn)，这是排序算法中的最优解！！！
- 其实Heapsort和Selectionsort的前缀都是数组，前者是优化后的树形结构(以数组形式存储)方便delMax()操作，后者则较为平坦(是随机序列，无任何优化处理)
- 也就是说两个前缀的数据结构一个是Heap堆，一个是普通数组
- 建堆的算法有很多，可以通过逐一插入来做，也有更高效的做法，此处不再赘述
- 逻辑上的堆顶(树根)就是物理上的第一个元素m，最后一个元素这里是x表示, 将m和x交换，将x倒栽到之前m的位置，然后做一个下滤操作
- 注意之前最后的元素x未必全局最小，所以下滤到上图示例的位置，而且下一个Max(用n表示)也就位了，恢复成一个有序的堆结构，这里仅作说明
- 由此可见，堆排序也属于Selectionsort的家族，也可以看做是一种特例

**Insertionsort**

<div align="center">
    <img width="600" src="./screenshot/107.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- ...
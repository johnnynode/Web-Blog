动态规划 Dynamic Programming(DP)
---

### 引语

- 算法的设计不是无中生有的而是有些套路和规律的
- 拿分而治之来说，其中是有一些假设的，假设可以把问题分开包括分得比较均匀
- 如果能做到这样，分治才能变成一个有效的策略，如果分出来的两个问题是有耦合的，此中有彼，彼中有此
- 也就是两个问题不是彼此独立，这时候就会出现很麻烦的事情，比如在企业中，就会出现内耗，资源的浪费
- 这就导致在某一方面工作量的巨大爆炸，因为这时候的沟通成本非常的巨大，工作的推进就会非常的困难
- 在算法中来说，这种爆炸是呈指数级别的，尤其是在递归的时候，动态规划可以有效的发现这一问题
- 当然它也不是万能的，动态规划可以解决问题彼此相关的子任务的同时工作，这些工作重复的东西很多
- 实际上，它只是用了我们常见的策略, 就是把重复的不该重复计算的东西节省下来，仅此而已
- 动态规划只是设计算法的有效的策略之一

### Fibonacci: Recursion 斐波那契数列计算

- 斐波那契数列举例：

<div align="center">
    <img width="400" src="./screenshot/162.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 斐波那契数的计算公式 $fib() = fib(n-1) + fib(2)$
- 这里的n从0开始，非负数，从2开始，每一项是前两项的和，这个数列其实是呈指数爆炸的
- 我们可以设计一个算法来表达这个公式 `int fib(n) {return (n<2) ? n : fib(n-1) + fib(n-2);}`
- 我们可以看到这个公式的数学定义是一种递归的形式，功能上没问题，我们要关心速度
- 在一般的计算机上，比如我们的笔记本在实现这一算法的时候就会在n=44左右的时候开始慢下来了，它会越来越慢
- 而且我们可以看到这一单线程的程序占用了一定量的CPU资源，我们知道这个算法是不太合理的，只能计算较小的数
- 我们可以简单的来分析一下，我们可以把任何一个递归算法在执行过程中生成的递归实例逐个画出来
- 每个递归实例用方框表示，里面写上数字，数字表示当前计算的项数

<div align="center">
    <img width="600" src="./screenshot/163.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 我们可以看到某种意义上来说这是一种分治，只是分的不好，一个是计算它的前一项，一个是计算前两项
- 在没有达到0, 1的时候，就会上行下效的进行递归计算，5分成4,3; 4分成3,2; 3分成2,1 ... 
- 直到图上的绿色方块，一旦碰到绿块，就会递归返回，从而自底而上，逐级拼凑，最终得到计算结果
- 我们可以看到为了计算第5项，竟然生成了这么多的递归实例，如果项数级别高了，我们已经预感到了爆炸
- 这些递归实例很多都是无谓的，也就是重复的，越是底层的递归实例，被调用的越频繁，这是上面算法的缺陷
- 我们可以用递推式来计算下时间
    * 1 ) $T(n) = T(n-1) + T(n-2) + 1 > 2 \cdot T(n-2) + 1 = O((\sqrt{2})^n)$
        * 在上面第一个式子中，求解第n项，分而治之转化为计算第n-1项和第n-2项，其时间复杂度分别为：$T(n-1), T(n-2)$
        * `+1` 是算法中的三目判断和加法计算所需时间
    * 2 ) $T(n) = T(n-1) + T(n-2) + 1 = O(fib(n+1)) = O(\phi^n), \phi = (1 + \sqrt{5}) / 2 = 1.618...$
        * 按照这种思路递推下去得到结果, 计算斐波那契数第n项的时间, 从渐进的来说就是斐波那契数本身，区别是向后平移一位`fib(n+1)`
        * 从常数意义上来说，无非是 $\phi^n$, 斐波那契数本身是有通项的，其通项取决于$\phi$和$\phi$的共轭数$(1 - \sqrt{5}) / 2$
        * $\phi$和它共轭的数一个是1.618，一个是0.618，二者就差了1, 通过Big-O记号来去粗存精，保留>1的项，也就是把$\phi$记下来
- 也就是说计算斐波那契数第n项的时间是$\phi^n$，我们知道>1的数字，其指数是爆炸型的
- 这里有一个技巧叫做"封底估算"(back-of-envelope evaluation), 也就是我们在信封的背面稍微划上几笔就能算出
- 为此我们要积累一些经验，懂得一些技巧，比如$10^3 \approx 2^{10}$, 对于$\phi$来说，$\phi^5 \approx 10$, 这个比较粗糙
- 有一个更接近的估算为：$\phi^{36} \approx 2^{25}$, 更好记的方式是：$\phi^{6^2} \approx 2^{5^2}$
- 我们一般的计算机用的都是GHZ, 其数值大概1s的吞吐量是$10^9 \approx 2^30 \approx \phi^{43}$
- 所以，我们可以看到为什么上述算法在计算40多项的时候开始变慢了，这是因为这时候计算该项CPU要跑1秒钟，所以人会感觉到延迟
- 如何解决这个慢的问题呢，我们就需要用到动态规划

### Fibonacci: Memoization 记忆化

- 通常的递归操作是在一次计算中，会通过一个递归实例唤醒另一个递归实例，接着继续唤醒下一个...最终协同计算出结果
- 如何避免递归中的重复事情，所谓记忆化就是好记性不如烂笔头，在计算过程中创建一个look-up table查询表
- 专门用于存储和查询，在Fibonacci这个案例中，可以把查询表设计成一个一维数组
- 将重复的数据存储在其中，经过一次查询即可知道是否进行复杂的递归操作
- 比如4这个递归实例, 先不贸然进行分治，因为贸然去做可能会演化出爆炸，所以需要慎重
- 可以现在这个查询表中查询一下，是否存在4所对应的结果，如果存在则直接返回，不存在，则递归并存储
- 每计算出一个值就将该值记录，下一次只需要查询就不必进行计算了，进而节省了大量重复的计算
- 在这个过程中，我们的时间收获会非常大，而只不过多了一张查询表，而这张表的空间并不大, 查询和存储时间也很快
- 不仅是Fibonacci这个案例，其他的一般递归计算也同样适用，比如下面这个比较简单但低效的算法
    ```python
    def f(n)
        if(n<1) return trivial(n) # 足够小的时候是一个trivial case
        return f(n-X) + f(n-Y) * f(n-Z); # 递归调用此前计算的各个项，这里不是Fibonacci的二分支了，而是三个，甚至可以是更多
    ```
- 通过look-up table进行改进，改进后的算法示例，伪代码实现
    ```python
    T M[N] # 初始化一个一维表, T表示基本类型视应用而定，N表示足够的项数

    def f(n)
        if(n<1) return trivial(n)
        # 必要时再递归并存储结果
        # 判断是否存在M[n]
        if(M[n] == UNDEFINED)
            M[n] = f(n-X) + f(n-Y) * f(n-Z)
        return M[n] # 将结果return出去
    ```
- 这时候，我们可以通过下图来看下节省后的时间，不失一般性，我们还用Fibonacci的案例

<div align="center">
    <img width="600" src="./screenshot/164.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 灰色部分是节省下来的递归实例，黄色的实例表示不用递归，直接终止
- 蓝色部分是真正有效的递归实例，可以看到没有重样的，特别说明一下黄色部分
    * 一些计算实例不仅可以提前终止，因为上层被提前终止了，所以它们实际上并不存在
    * 不存在是指不会被生成出来，当然从逻辑上来说是存在的，实际上不会花费任何时间
- 这样就解决了指数爆炸的问题，所以这是一个非常好的解决方案
- 动态规划就是这样一种解决指数爆炸的问题
###  BST & BBST

- BST(Binary Search Tree) 二叉搜索树，也就是使用二叉树来做查找
- BBST(Balanced Binary Search Tree) 平衡二叉搜索树

1 ) **BST**

<div align="center">
    <img width="600" src="./screenshot/60.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 比如我们有一堆书，需要经常在其中找到某一本数，如何有效查找呢？
- 将所有的书先做一遍预处理：编个号，排个序，接下来就可以很方便的在其中做查找
- 树的查找每次都是从根部开始进行比较，比较之后将我们的目光转向其中一侧，比如说如果我搜索是28或29
- 28 > 20, 所以, 20左边的全部都不需要看了，我们现在看右边，其实右边本质上是一个规模缩小的子树，sub tree
- 38 > 28, 所以, 我们只需要关注这棵子树的左侧即可，按照这种方式，逐次比较，不断深入, 直到找到29号元素
- 如果我们搜索条件的是28，那么可见经过比较，提示找不到元素，如果搜索的是29，那么直接返回，提示找到即可
- 这样做的好处是既可以完成所有的查找却不需要将所有元素都遍历一次
- 对树的预处理是：对于任何一个位置，所有的左后代都比它小，所有的右后代都比它大
- 这种树查找在一般的时候性能不错，但是它的弱点在那些深的一些位置上

2 ) **BBST**

<div align="center">
    <img width="600" src="./screenshot/61.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 在上面的场景中，如果要找较深的节点，显然会花更多的时间，需要更多的比较，就像哈夫曼编码一样，需要更多的比特
- 有一种技巧就是把这种树平衡化，不仅在一开始是平衡的，而且在所有的操作，插入和删除都可以保持一个平衡态
- 即便要攻击它最弱的一点，也不至于太弱，这就是BBST

### Hashtable + Dicionary + Map

- 很多时候我们希望直接找到某个东西，如：

```python
beauty = dict({
    "沉鱼":"西施",
    "落雁":"昭君",
    "闭月":"貂蝉",
    "羞花":"玉环"
})
beauty["红颜"] = "圆圆"
print beauty

for alias, name in beauty.items():
    print alias, ":", name
```

- 这种直接找到某个东西的方法是非常的快
- 这种方法我们一般叫做 Hashtable 散列表或哈希表
- 它的内部其实是先准备好了一个数组(数组的好处是查找非常快，一下就能找出来)

<div align="center">
    <img width="600" src="./screenshot/62.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 这里有 (0 ~ 46) 47个元素, 如果这个值是156，那么关于47的模余就是15，那么156就存储于15这个位置上
- 当有很多数，我们都想存储于这个数组中，那么就会有位置的冲突，如：768 和 580，这时候，我们通过List来存储冲突的元素
- 按照这种结构来组织成一个叫散列表的数据结构
- 查找的时候，任何查找的对象都可以把它转换成数字，取模以后，对应到数组中的某一个，之后顺着里面的List查找
- 如果有的话则找到, 没有则报告查找失败
- 散列表最重要的事情是如何做映射，映射有很多种，我们上面使用取模的方式
- 这个模在数学上叫做mod, 在很多语言中用 % 表示
- 直接对某一个数取模，一般这个数就取这个散列表的长度，就像上面的47，但是这里我们倾向于取值 90001
- 同时，这个值我们倾向于取素数，这样的话我们可以很方便的进行查找
- 我们看到一旦底层用了Hashtable, 那么接近于在常数时间内找出任何一个元素对应的值
- 在python中的dict, map存储查询等操作起来非常快的原因就是这个底层机制

### Priority Queue ~ Heap

1 ) **对比Huffman Tree的问题**

- 在之前的Huffman Tree中我们知道它是维护了一棵森林，每个元素都是一棵树，都有各自的权重
- Huffman的策略是挑2个最小的，通过引入一个新节点将这两个最小的合二为一，将新节点这棵树重新插回森林
- 这一过程，森林中少了一棵树(出了2个，进去1个，净损失1个)，反复这么处理
- 我们知道这个过程从n到1，总共有n-1次的迭代
- 我们如何将这个结构组织起来，方便我们快捷的找到权重最小的两个，是我们需要讨论的问题
- 之前我们用的方式是通过Vector或List的结构，找到其中最小的两个，需要逐个比较，这个过程需要n的时间
- 所以，总计是 n*(n-1)的时间，也就是时间复杂度为：$O(n^2)$
- 我们可以看出这个n-1次的迭代是无法进行优化的，是必须的过程
- 而每一次的迭代需要花n的时间(这个n的时间是在n棵树中找出最小的两个), 这个n的时间这块可以优化

2 ) **引出Priority Queue ~ Heap数据结构**

- 如何优化呢？我们需要使用一个新的数据结构，一种三角形的树形结构，可以方便的进行`getMin()`, `delMin()`等操作
- 这时候找出两个最小树的时间复杂度为O(logn), 总体时间复杂度为：O(nlogn) 我们把这种数据结构叫做 Heap 堆
- 以Heap为代表的这一类问题，我们统一称之为 Priority Queue 优先级队列

<div align="center">
    <img width="600" src="./screenshot/63.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 如上图，它看上去是一棵树，对应的可以存成一个向量，它可以很方便的进行`getMax()`或`getMin()`操作，也可以以同样的效率支持`insert(x)`操作
- 它会把你需要的max或min放到你唾手可得的地方(树根或堆顶)，也就是说我们在取一个元素的时候不是看谁大或谁近，而是看谁优先级最高

3 ) **Huffman Tree的另一种优化方案**

- 而针对Huffman Tree的问题，我们并不一定要用 Priority Queue ~ Heap 这个数据结构，我们可以通过Stack + Queue的方式模拟出来O(nlogn)的解决方案

<div align="center">
    <img width="600" src="./screenshot/64.jpg">
    <br />
    <div style="text-align:center">备注：图片托管于github，请确保网络的可访问性</div>
    <br />
</div>

- 当我们拿到了一组哈夫曼要编码的字符的频率表之后，首先把他们全部排序，如：2, 5, 13, 16, 19, 37 
    * 这一步排序，我们不推荐使用时间复杂度为$O(n^2)$的bubble sort来排序, 我们使用更快的方式来处理，这一步时间复杂度记为：O(nlogn)
- 之后将排好序的元素通过栈来组织起来(最小元素存放于栈顶位置), 还需要一个辅助的数据结构为队列
- 在第一次中，我们在栈中找到最小的两个: 2,5(栈顶和次栈顶), 通过合并为7, 存入队列中，完成首次迭代
- 进而，在栈和队列中找到最小的两个元素: 13, 7, 通过合并为20, 存进队列中, 完成第二次迭代
- 再次，在栈和队列中找到最小的两个元素: 16, 19, 通过合并为35, 存进队列中, 完成第三次迭代
- 继续, 在栈和队列中找到最小的两个元素: 20, 35, 通过合并为55, 存进队列中, 完成第四次迭代
- 最后, 在栈和队列中还剩两个元素：37, 55, 合并它们, 得到了最终的92
- 在这个过程中，我们同样构造出来了Huffman Tree, 我们依赖全是栈和队列的操作，每个操作都是常数时间
- 总共有n步，每一步常数，所有的时间为O(n), 这是一个线性的复杂度
- 这里面的奥妙是：
    * 在任何一个时刻，如果在整个森林中挑选最小的两个, 只要在栈和队列这两个子集中挑选即可
    * 无论任何时候，栈亦或是队列中的元素都是有序分布的
    * 无论在栈还是在队列中找，只需要考虑前面的两个，充其量4个元素就够了
    * 可能最小的两个元素只来自于栈或只来自于堆或一个来自于栈，一个来自于堆
    * 这样每一次比较都是常数，整体上来说就是线性的

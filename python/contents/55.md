### 爬虫简介

通过程序来爬取商城图片信息并存储于本地的项目

### 相关说明

1）解决https警告信息(`ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed`)的代码

```python
import ssl
import logging

logging.captureWarnings(True) # 在调用 requests.get 时的处理
ssl._create_default_https_context = ssl._create_unverified_context # 在调用urlretrieve时的处理
```

2）对于urlretrieve之前较麻烦的做法

```python
    # 默认情况下，当您发出请求时，响应正文会立即下载，而设置stream参数为true，则只有响应头已经下载并且连接保持打开状态。
    with requests.get(imurl, stream=True) as ir: # 使用with的好处不用考虑close关闭问题。
        with open('./mypic/p'+str(m)+'.jpg', 'wb') as f:
            for chunk in ir:
                f.write(chunk)
```

3) 在代码同级目录下建立mypic目录，当然也可以程序处理，这里只作为快速演示

### 全部代码

[点击这里查看京东图片信息抓取案例](https://github.com/johnnynode/python-spider/blob/master/contents/code/pro8.py)

### 备注说明

如果想要爬取分页信息，像之前处理豆瓣网数据一样，分析分页参数并处理即可，详情可查看前博文。